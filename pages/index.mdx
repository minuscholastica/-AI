import { Callout, Steps, Step } from "nextra-theme-docs";

# 소개

대규모 언어 모델(Large Language Model, LLM), 검색 보조 생성(Retrieval Augmented Generation, RAG), 그리고 임베딩(Embedding)은 최근 자연어 처리(Natural Language Processing, NLP) 분야에서 주목받고 있는 혁신적인 기술들입니다. 이들 기술은 인공지능이 자연어를 더욱 깊이 있게 이해하고 생성할 수 있게 해줍니다.

<Callout emoji="💡">
LLM, RAG, 임베딩 기술은 AI 시스템이 자연어를 보다 자연스럽고 인간다운 방식으로 처리할 수 있도록 해줍니다.
</Callout>

## LLM(대규모 언어 모델)

LLM은 엄청난 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 대규모 인공지능 모델입니다. 이전 언어 모델들이 특정 과제에 국한되었던 것과 달리, LLM은 일반적인 언어 지식을 습득하여 다양한 영역에 활용될 수 있습니다.

[ChatGPT](/what-is-llm)는 LLM의 대표적인 예시로, 사용자와 대화하며 질문에 답변하고 다양한 작업을 수행할 수 있습니다.

## RAG(검색 보조 생성)

RAG는 LLM의 언어 생성 능력에 검색 기능을 결합한 기술입니다. LLM이 문장을 생성할 때, RAG는 관련 정보를 외부 데이터베이스에서 검색하여 LLM에 제공함으로써 더 정확하고 풍부한 응답을 만들어 냅니다.

[RAG](/what-is-rag)는 LLM의 지식 부족을 보완하고 맥락 이해를 높여줍니다.

## 임베딩

임베딩은 자연어를 숫자 벡터로 인코딩하는 기술입니다. 문장이나 단어를 벡터 공간에 매핑함으로써 컴퓨터가 이해하기 쉬운 형태로 변환됩니다. 

임베딩은 [LLM과 RAG](/role-of-embeddings)에서 중요한 역할을 합니다. 특히 RAG에서 임베딩은 질의와 데이터 소스의 관련성을 측정하는데 사용됩니다.

이 문서에서는 LLM, RAG, 임베딩 기술의 작동 원리와 활용 사례, 장단점 등을 자세히 살펴볼 것입니다. 또한 이들 기술이 자연어 처리 분야에 어떤 영향을 미치고 있는지 알아보겠습니다.