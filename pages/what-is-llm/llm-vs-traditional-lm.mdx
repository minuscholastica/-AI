import { Callout, Steps, Step } from "nextra-theme-docs";

# LLM과 전통적 언어 모델의 차이

대규모 언어 모델(LLM)은 전통적인 언어 모델과 비교했을 때 몇 가지 중요한 차이점이 있습니다. 주요 차이점은 다음과 같습니다.

1. **일반 목적 vs. 특정 과제**

<Callout emoji="💡">
전통적 언어 모델은 특정 과제(예: 기계 번역, 텍스트 요약, 문장 완성 등)를 수행하도록 설계되었습니다. 반면 LLM은 일반적인 자연어 이해 및 생성 능력을 갖추고 있어, 다양한 자연어 처리 과제에 활용될 수 있습니다.
</Callout>

2. **학습 데이터의 크기**

```mermaid
pie
    title 전통적 언어 모델 데이터셋 크기
    "수백만 단어" : 90
    "수억 단어" : 10
pie
    title LLM 데이터셋 크기 
    "수백억 단어" : 50
    "수조 단어" : 50
```

LLM은 수백억 단어 이상의 거대한 텍스트 데이터셋으로 훈련되었습니다. 이는 전통적 언어 모델이 훈련되는 데이터셋보다 훨씬 큰 규모입니다. 

3. **성능 차이**

<Callout emoji="✨">
일반적으로 LLM은 전통적 언어 모델보다 다양한 자연어 처리 과제에서 뛰어난 성능을 보입니다. 특히 문맥 이해, 생성 능력, 추론 능력 등에서 LLM이 우수한 것으로 알려져 있습니다.
</Callout>

하지만 성능 차이는 과제와 평가 방식에 따라 다를 수 있습니다. 특정 과제에 특화된 전통적 모델이 더 좋은 성능을 낼 수도 있습니다.

<Steps>

### 정리

1. LLM은 일반 목적 자연어 능력을 갖추고 있는 반면, 전통적 언어 모델은 특정 과제에 특화되어 있습니다.
2. LLM은 수백억 단어 이상의 거대한 텍스트 데이터셋으로 훈련되었지만, 전통적 모델은 상대적으로 작은 데이터셋을 사용했습니다.
3. 일반적으로 LLM이 다양한 자연어 처리 과제에서 뛰어난 성능을 보이지만, 특정 과제에서는 전통적 모델이 더 좋은 성능을 낼 수 있습니다.

</Steps>

이처럼 LLM과 전통적 언어 모델은 목적, 학습 데이터, 성능 측면에서 차이가 있습니다. 이런 차이점 때문에 LLM은 언어 이해와 생성 분야에서 새로운 가능성을 열어주고 있습니다. 하지만 아직 해결해야 할 과제도 남아 있습니다. 이에 대해서는 [이후 섹션](/llm-training-deployment-challenges)에서 자세히 다루겠습니다.